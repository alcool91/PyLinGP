{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b2b05ac-89bf-4afa-a842-b01d72078c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Program import Program, Instruction, CASES, MIN_LENGTH, MAX_LENGTH\n",
    "import Selection\n",
    "import random\n",
    "import pickle\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0011603-95c7-4078-bcaf-8e1315e32f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand():\n",
    "    \"\"\" Generates a Random Program \"\"\"\n",
    "    random_program = Program(IS=['Add', 'Sub', 'Mul', 'Div', 'Mean', 'Copy', 'Sqrt'])\n",
    "    return random_program\n",
    "\n",
    "def I(program, inp):\n",
    "    \"\"\" Runs 'program' on input inp. Clips the return value to lie in [-1,1] as per the HW instructions \"\"\"\n",
    "    program.reset()\n",
    "    program._set_input(inp)\n",
    "    return_val = program.execute()\n",
    "    # if return_val > 1:\n",
    "    #     return 1\n",
    "    # if return_val < -1:\n",
    "    #     return -1\n",
    "    return return_val\n",
    "\n",
    "def f(program, gen, cases=CASES):\n",
    "    \"\"\" Returns the sum of the squared error on the fitness cases for evaluating sin \"\"\"\n",
    "    F1_AMELIORATION = 2_500\n",
    "    fitness = 0\n",
    "    dif     = 0\n",
    "    outs    = []\n",
    "    fitness_1 = 0\n",
    "    fitness_2 = 0\n",
    "    out_counts = {}\n",
    "    for i in range(len(cases)):\n",
    "        tv = math.sin(cases[i])     #true value of sin for the fitness case\n",
    "        rv = I(program, cases[i])   #return value of the program evaluated on the fitness case\n",
    "        outs.append(rv) \n",
    "        fitness_1 += math.sqrt((rv-tv)**2)\n",
    "        for out in outs:\n",
    "            if out in out_counts.keys():\n",
    "                out_counts[out] += 1\n",
    "            else:\n",
    "                out_counts[out] = 1\n",
    "        for out_count in out_counts.keys():\n",
    "            if out_counts[out_count] > 1:\n",
    "                fitness_2 += out_counts[out_count]**2\n",
    "    fitness = max([(1-(gen/F1_AMELIORATION)), 0])*fitness_2 + min([(gen/F1_AMELIORATION), 1])*fitness_1 \n",
    "    return fitness\n",
    "\n",
    "def f1(program, cases=CASES):\n",
    "    F1_AMELIORATION = 2_500\n",
    "    fitness = 0\n",
    "    dif     = 0\n",
    "    outs    = []\n",
    "    fitness_1 = 0\n",
    "    fitness_2 = 0\n",
    "    out_counts = {}\n",
    "    for i in range(len(cases)):\n",
    "        tv = math.sin(cases[i])     #true value of sin for the fitness case\n",
    "        rv = I(program, cases[i])   #return value of the program evaluated on the fitness case\n",
    "        outs.append(rv) \n",
    "        fitness_1 += math.sqrt((rv-tv)**2)\n",
    "    \n",
    "    #     for out in outs:\n",
    "    #         if out in out_counts.keys():\n",
    "    #             out_counts[out] += 1\n",
    "    #         else:\n",
    "    #             out_counts[out] = 1\n",
    "    #     for out_count in out_counts.keys():\n",
    "    #         if out_counts[out_count] > 1:\n",
    "    #             fitness_2 += out_counts[out_count]**2\n",
    "    # fitness = max([(1-(gen/F1_AMELIORATION)), 0])*fitness_2 + min([(gen/F1_AMELIORATION), 1])*fitness_1 \n",
    "    return fitness_1\n",
    "    \n",
    "    \n",
    "def f2(program, generation=None, cases=CASES):\n",
    "    F1_AMELIORATION = 2_500\n",
    "    fitness = 0\n",
    "    dif     = 0\n",
    "    outs    = []\n",
    "    fitness_1 = 0\n",
    "    fitness_2 = 0\n",
    "    out_counts = {}\n",
    "    for i in range(len(cases)):\n",
    "        #tv = math.sin(cases[i])     #true value of sin for the fitness case\n",
    "        rv = I(program, cases[i])   #return value of the program evaluated on the fitness case\n",
    "        outs.append(rv) \n",
    "        #fitness_1 += math.sqrt((rv-tv)**2)\n",
    "    for out in outs:\n",
    "        if out in out_counts.keys():\n",
    "            out_counts[out] += 1\n",
    "        else:\n",
    "            out_counts[out] = 1\n",
    "    for out_count in out_counts.keys():\n",
    "        if out_counts[out_count] > 1:\n",
    "            fitness_2 += out_counts[out_count]**2\n",
    "    # fitness = max([(1-(gen/F1_AMELIORATION)), 0])*fitness_2 + min([(gen/F1_AMELIORATION), 1])*fitness_1 \n",
    "    return fitness_2\n",
    "\n",
    "def mut(program):\n",
    "    #PROBABILITIES TO\n",
    "    ADD_P = 0.0095   #Add a random instruction in a random location\n",
    "    REM_P = 0.006   #Delete a random instruction\n",
    "    NAM_P = 0.005   #Change the name of an instruction (and therefore its type)\n",
    "    ARG_P = 0.005   #Change an argument of an instruction\n",
    "    SWP_P = 0.005   #Swap two instructions\n",
    "    \n",
    "    if random.random() < ADD_P:  #Add instruction\n",
    "        if (len(program.INST) < MAX_LENGTH):\n",
    "            rand_inst = Instruction(len(program.WREG), len(program.CREG), instruction_set=program.IS)\n",
    "            loc       = random.randint(0, len(program.INST))\n",
    "            program.INST.insert(loc, rand_inst)\n",
    "            \n",
    "    if random.random() < REM_P:  #Remove instruction\n",
    "        if (len(program.INST) > MIN_LENGTH):\n",
    "            loc       = random.randint(0, len(program.INST)-1)\n",
    "            program.INST.pop(loc)\n",
    "            \n",
    "    if random.random() < NAM_P:  #Change an instruction name\n",
    "        if(len(program.INST) > 1):\n",
    "            loc = random.randint(0, len(program.INST)-1)\n",
    "            program.INST[loc]._set_name(random.choice(program.IS))\n",
    "        \n",
    "    if random.random() < ARG_P:   #Change argument to an instruction\n",
    "        if(len(program.INST) > 1):\n",
    "            inst_loc = random.randint(0, len(program.INST)-1)\n",
    "            arg_loc  = random.randint(0,2)\n",
    "            if arg_loc == 1:\n",
    "                program.INST[inst_loc]._set_op1(random.randint(0, len(program.REG)))\n",
    "            if arg_loc == 2:\n",
    "                program.INST[inst_loc]._set_op2(random.randint(0, len(program.REG)))\n",
    "            if arg_loc == 0:\n",
    "                program.INST[inst_loc]._set_dest(random.randint(0, len(program.WREG)))\n",
    "            \n",
    "    if random.random() < SWP_P:   #Swap the index of two instructions\n",
    "        if (len(program.INST) > 1):\n",
    "            loc1 = random.randint(0, len(program.INST)-1)\n",
    "            loc2 = random.randint(0, len(program.INST)-1)\n",
    "            temp = program.INST[loc1]\n",
    "            program.INST[loc1] = program.INST[loc2]\n",
    "            program.INST[loc2] = temp\n",
    "            \n",
    "def XOver(prog1, prog2):\n",
    "    \"\"\" Crossover Function chooses 2 random crossover points (one for each individual)\n",
    "        Swaps the second part of program 2's instructions with the first part of program 1's instructions \"\"\"\n",
    "    #TODO: Make sure Xover cannot create programs that are too long!\n",
    "    #Maybe determine the length of each program after loc1 and loc2 are selected and modify if one would be too long\n",
    "    length_after_Xover_prog1 = MAX_LENGTH + 1\n",
    "    length_after_Xover_prog2 = MAX_LENGTH + 1\n",
    "    \n",
    "    if ((len(prog1.INST) > 1) and (len(prog2.INST) > 1)):\n",
    "        while(length_after_Xover_prog1 > MAX_LENGTH or length_after_Xover_prog2 > MAX_LENGTH):\n",
    "            loc1 = random.randint(0, len(prog1.INST)-1)\n",
    "            loc2 = random.randint(0, len(prog2.INST)-1)\n",
    "            temp1 = prog1.INST[:loc1]\n",
    "            temp2 = prog2.INST[loc2:]\n",
    "            length_after_Xover_prog1 = len(temp2 + prog1.INST[loc1:])\n",
    "            length_after_Xover_prog2 = len(prog2.INST[:loc2] + temp1)\n",
    "        prog1.INST = temp2 + prog1.INST[loc1:]\n",
    "        prog2.INST = prog2.INST[:loc2] + temp1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f633c2fc-ca25-45be-bd4a-fee00d30bd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "dataF = load_breast_cancer(as_frame=True)['data']\n",
    "data  = load_breast_cancer()['data']\n",
    "target = load_breast_cancer()['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adb2a5ed-c86b-4431-85bc-5e7918378c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test1, y_train, y_test1 = train_test_split(data, target, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test       = train_test_split(X_test1, y_test1, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1e1eb19-252e-48c9-9a69-0340ba98f227",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "def f3(program, cases=X_train):\n",
    "    outs = []\n",
    "    for row in range(len(X_train)):\n",
    "        tv = y_train[row]           #true value of sin for the fitness case\n",
    "        #print(program)\n",
    "        program.reset()             #return value of the program evaluated on the fitness case\n",
    "        program._set_inputs(cases[row])\n",
    "        #print(program)\n",
    "        rv = program.execute()\n",
    "        outs.append(rv) \n",
    "    if (max(outs) - min(outs) != 0):\n",
    "        outs = [(float(i)-min(outs))/(max(outs)-min(outs)) for i in outs]\n",
    "    elif max(outs) != 0:\n",
    "        outs = [(float(i))/(max(outs)) for i in outs]\n",
    "    fitness1 = roc_auc_score(y_train, outs)\n",
    "        #fitness_1 += math.sqrt((rv-tv)**2)\n",
    "    \n",
    "    #     for out in outs:\n",
    "    #         if out in out_counts.keys():\n",
    "    #             out_counts[out] += 1\n",
    "    #         else:\n",
    "    #             out_counts[out] = 1\n",
    "    #     for out_count in out_counts.keys():\n",
    "    #         if out_counts[out_count] > 1:\n",
    "    #             fitness_2 += out_counts[out_count]**2\n",
    "    # fitness = max([(1-(gen/F1_AMELIORATION)), 0])*fitness_2 + min([(gen/F1_AMELIORATION), 1])*fitness_1 \n",
    "    return fitness1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ec31a1c-138c-44d7-b0f7-8d21e17ef66c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation:  1\n",
      "----------NEW BEST FITNESS---------------\n",
      "0.5\n",
      "[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09090909090909091, 0.0, 1.3956124250860895, 0.0, -2.0, -1.0, 1.0, 0.5, 0.3333333333333333, 0.25, 0.2, 12.18, 20.52, 77.22, 458.7, 0.08013, 0.04038, 0.02383, 0.0177, 0.1739, 0.05677, 0.1924, 1.571, 1.183, 14.68, 0.00508, 0.006098, 0.01069, 0.006797, 0.01447, 0.001532, 13.34, 32.84, 84.58, 547.8, 0.1123, 0.08862, 0.1145, 0.07431, 0.2694, 0.06878]\n",
      "Exp(19,24,11)\n",
      "Sub(10,10,18)\n",
      "Mean(17,17,23)\n",
      "Mean(23,18,8)\n",
      "Sub(11,7,6)\n",
      "Exp(27,19,21)\n",
      "Mean(8,18,19)\n",
      "Sqrt(12,11,20)\n",
      "Min(20,21,3)\n",
      "Div(30,22,22)\n",
      "Div(24,26,23)\n",
      "Log(17,15,18)\n",
      "Sqr(24,9,8)\n",
      "Max(7,19,0)\n",
      "Sqrt(6,6,12)\n",
      "Copy(4,20,17)\n",
      "Div(20,11,5)\n",
      "\n",
      "----------NEW BEST FITNESS---------------\n",
      "0.929273389332561\n",
      "[-4.153151630887583, 1.0, 1.0, 24.36, 0.0, 4.935585071701226, -0.25, 0.0, -0.8414709848078965, 24.36, 0.0, 0.4112987559751021, -4.153151630887583, 4.153151630887583, 0.0, 0.0, 17.248668469144192, 1.6161982319408212, 0.0, 0.0, 0.6635116636975381, 4.935585071701226, 0.0, 0.0, -1.0, 1.0, 0.5, 0.3333333333333333, 0.25, 0.2, 12.18, 20.52, 77.22, 458.7, 0.08013, 0.04038, 0.02383, 0.0177, 0.1739, 0.05677, 0.1924, 1.571, 1.183, 14.68, 0.00508, 0.006098, 0.01069, 0.006797, 0.01447, 0.001532, 13.34, 32.84, 84.58, 547.8, 0.1123, 0.08862, 0.1145, 0.07431, 0.2694, 0.06878]\n",
      "Add(10,6,19)\n",
      "Min(18,14,10)\n",
      "Max(19,19,4)\n",
      "Mean(6,2,18)\n",
      "Sqrt(4,18,7)\n",
      "Div(19,7,11)\n",
      "Exp(3,4,13)\n",
      "Sub(7,28,17)\n",
      "Mean(2,13,20)\n",
      "Add(13,9,6)\n",
      "Copy(8,12,19)\n",
      "Sub(26,21,8)\n",
      "Log(13,6,23)\n",
      "Sqrt(13,4,1)\n",
      "Exp(19,25,2)\n",
      "Sin(19,0,15)\n",
      "Mean(15,15,11)\n",
      "Copy(14,19,14)\n",
      "Sqrt(12,16,11)\n",
      "Div(30,8,9)\n",
      "Sqrt(9,8,21)\n",
      "Mul(21,20,11)\n",
      "Min(23,1,6)\n",
      "Exp(14,12,5)\n",
      "Mean(3,30,17)\n",
      "Sin(24,6,8)\n",
      "Max(9,19,3)\n",
      "Mul(8,21,13)\n",
      "Min(25,10,0)\n",
      "Sqrt(15,7,13)\n",
      "Mean(12,21,20)\n",
      "Max(23,13,5)\n",
      "Exp(16,29,2)\n",
      "Add(0,12,12)\n",
      "Sqr(0,12,16)\n",
      "Div(12,24,13)\n",
      "\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.4920454752348245\n",
      "Generation:  2\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.5032436587081557\n",
      "Generation:  3\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.5114480696817973\n",
      "Generation:  4\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.528874601729631\n",
      "Generation:  5\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.572711041916662\n",
      "Generation:  6\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.6529419663177044\n",
      "Generation:  7\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.7312720859022633\n",
      "Generation:  8\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.8076490462200542\n",
      "Generation:  9\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.8524189390491201\n",
      "Generation:  10\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.8702724065874995\n",
      "Generation:  11\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.8764727624446605\n",
      "Generation:  12\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.8730385753299998\n",
      "Generation:  13\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.8756007779203091\n",
      "Generation:  14\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.8768740327719664\n",
      "Generation:  15\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.8743263954979977\n",
      "Generation:  16\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.8777605826126582\n",
      "Generation:  17\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.8767867132867179\n",
      "Generation:  18\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.872100446890392\n",
      "Generation:  19\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.8786191293913234\n",
      "Generation:  20\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.8734678487193325\n",
      "Generation:  21\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.8786191293913235\n",
      "Generation:  22\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.8751849422766628\n",
      "Generation:  23\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.8734678487193326\n",
      "Generation:  24\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.8738971221086651\n",
      "Generation:  25\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.8773313092233257\n",
      "Generation:  26\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.876393180783718\n",
      "Generation:  27\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.8790250134480951\n",
      "Generation:  28\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.8747759858484757\n",
      "Generation:  29\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.8764727624446607\n",
      "Generation:  30\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.8764727624446604\n",
      "Generation:  31\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.8769020358339932\n",
      "Generation:  32\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.8791279844415988\n",
      "Generation:  33\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.8748352505482727\n",
      "Generation:  34\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.8743263954979975\n",
      "Generation:  35\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.876043489055328\n",
      "Generation:  36\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.8733882670583899\n",
      "Generation:  37\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.8799069495593212\n",
      "Generation:  38\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.8779136529151369\n",
      "Generation:  39\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.8799069495593214\n",
      "Generation:  40\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.878189856001991\n",
      "Generation:  41\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.8755346340050528\n",
      "Generation:  42\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.8717507551620022\n",
      "Generation:  43\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.8717472586585058\n",
      "Generation:  44\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.8793296540737418\n",
      "Generation:  45\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.8777605826126583\n",
      "Generation:  46\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.8777517068730133\n",
      "Generation:  47\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.8756107191624991\n",
      "Generation:  48\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.8777605826126582\n",
      "Generation:  49\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.8777605826126582\n",
      "Generation:  50\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.8777605826126582\n",
      "Generation:  51\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.8811151880663763\n",
      "Generation:  52\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.8768777051351061\n",
      "Generation:  53\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.876393180783718\n",
      "Generation:  54\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.876393180783718\n",
      "Generation:  55\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.8773313092233258\n",
      "Generation:  56\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.8789688211197135\n",
      "Generation:  57\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.870892208383337\n",
      "Generation:  58\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.8773313092233258\n",
      "Generation:  59\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.8773313092233257\n",
      "Generation:  60\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.8743263954979976\n",
      "Generation:  61\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.8751053606157202\n",
      "Generation:  62\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.8751849422766628\n",
      "Generation:  63\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.8760434890553281\n",
      "Generation:  64\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.8778401228948614\n",
      "Generation:  65\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.8777605826126583\n",
      "Generation:  66\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.8734678487193325\n",
      "Generation:  67\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.8772726031365131\n",
      "Generation:  68\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.8794776761699886\n",
      "Generation:  69\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.8756142156659953\n",
      "Generation:  70\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.8760434890553279\n",
      "Generation:  71\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.8790365684611294\n",
      "Generation:  72\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.8764376318947371\n",
      "Generation:  73\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.8763889394629086\n",
      "Generation:  74\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.877351626184471\n",
      "Generation:  75\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.8776810009517156\n",
      "Generation:  76\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.8781898560019908\n",
      "Generation:  77\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.8764484317457736\n",
      "Generation:  78\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.8755346340050527\n",
      "Generation:  79\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.879048402780656\n",
      "Generation:  80\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.8743324988620892\n",
      "Generation:  81\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.8769020358339932\n",
      "Generation:  82\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.8769020358339932\n",
      "Generation:  83\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.8746760872263877\n",
      "Generation:  84\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.8785846919352883\n",
      "Generation:  85\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.8753717983200279\n",
      "Generation:  86\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.8768224541730506\n",
      "Generation:  87\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.8797462138453311\n",
      "Generation:  88\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.8797235176066585\n",
      "Generation:  89\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.8806859146770438\n",
      "Generation:  90\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.8790483200231768\n",
      "Generation:  91\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.8738970393511858\n",
      "Generation:  92\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.879048402780656\n",
      "Generation:  93\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.8734678487193325\n",
      "Generation:  94\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.8747556688873304\n",
      "Generation:  95\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.8733882670583899\n",
      "Generation:  96\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.8784285285720245\n",
      "Generation:  97\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.8816240431166514\n",
      "Generation:  98\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.8811913559813016\n",
      "Generation:  99\n",
      "Best Fitness:  0.929273389332561\n",
      "Avg  Fitness:  0.8786191293913235\n"
     ]
    }
   ],
   "source": [
    "POP_SIZE       = 1000\n",
    "XOVER_P        = 0.009\n",
    "ELITE_K        = int(POP_SIZE*0.1)#50\n",
    "population     = [Program(reg_init='z', IS=['Add', 'Sub', 'Mul', 'Div', 'Mean', 'Copy', 'Sqrt', 'Sin', 'Max', 'Min','Sqr', 'Exp', 'Log' ]) for i in range(POP_SIZE)] # Start with a population of 500 random programs\n",
    "best_fitness_c = -1                   # Start this very high since even a random program will beat it\n",
    "best_prog_c    = None                       # Keep track of the best program\n",
    "tolerance      = 1                          # Stop searching when the best program has a fitness less than 1 (we want to minimize error)\n",
    "generation     = 1\n",
    "\n",
    "best_fitnesses_generation_c = []\n",
    "avg_fitnesses_generation_c  = []\n",
    "\n",
    "#TODO: Consider a fitness function that encourages putting DIFFERENT functions of the input in different registers. 10_000\n",
    "#      is too big for a population and XOVER and mutation probabilities should be lowered.\n",
    "\n",
    "\n",
    "\n",
    "logfile = open('log4.txt', 'w+')\n",
    "\n",
    "while (generation < 100):\n",
    "    if (generation % 100 < 10):\n",
    "        dumpfile='./saved_generations/generation'+str(generation)+'.pkl'\n",
    "        with open(dumpfile, 'wb+') as du:\n",
    "            pickle.dump(population, du)\n",
    "    print('Generation: ', generation)\n",
    "    this_gen_fitness_c= []\n",
    "    for individual in population:\n",
    "        ind_fit = f3(individual)\n",
    "        this_gen_fitness_c.append(ind_fit)\n",
    "        if ind_fit > best_fitness_c:\n",
    "            print('----------NEW BEST FITNESS---------------')\n",
    "            print(ind_fit)\n",
    "            print(individual)\n",
    "            best_fitness_c = ind_fit\n",
    "            best_prog_c    = individual\n",
    "    best_fitnesses_generation_c.append(max(this_gen_fitness_c))\n",
    "    avg_fitnesses_generation_c.append(sum(this_gen_fitness_c)/len(this_gen_fitness_c))\n",
    "    logfile.write('-----------------GENERATION ' + str(generation) + '---------------------------\\n')\n",
    "    logfile.write(\"Fitnesses: [\" + \", \".join(str(item) for item in this_gen_fitness_c) + \"]\\n\")\n",
    "    logfile.write('best fitness: ' +  str(best_fitnesses_generation_c[-1]) + \"\\n\")\n",
    "    logfile.write('avg fitnesses: ' +  str(avg_fitnesses_generation_c[-1]) + \"\\n\")\n",
    "    print('Best Fitness: ', best_fitnesses_generation_c[-1])\n",
    "    print('Avg  Fitness: ', avg_fitnesses_generation_c[-1])\n",
    "    elite = Selection.elite_selection(population, f3, X_train, k=int(POP_SIZE/10), opt_max=True)\n",
    "    tournament = Selection.tournament_selection(population, f3, X_train, next_gen_size=int((POP_SIZE*8)/10), opt_max=True)\n",
    "    randos     = [Program(reg_init='z', IS=['Add', 'Sub', 'Mul', 'Div', 'Mean', 'Copy', 'Sqrt', 'Sin', 'Max', 'Min','Sqr', 'Exp', 'Log' ]) for i in range(int(POP_SIZE/10))]\n",
    "    # while(len(next_gen) < POP_SIZE-(POP_SIZE/10)): #Fill the next gen with tournament selection up to 90%\n",
    "    #     r1 = random.randint(0, POP_SIZE-1)\n",
    "    #     r2 = random.randint(0, POP_SIZE-1)\n",
    "    #     if this_gen_fitness[r1] < this_gen_fitness[r2]:\n",
    "    #         next_gen.append(population[r1]._clone())\n",
    "    #     else:\n",
    "    #         next_gen.append(population[r2]._clone())\n",
    "            \n",
    "    # while(len(next_gen) < POP_SIZE):              #Fill the rest of the population with random programs\n",
    "    #     next_gen.append(Program(reg_init='z'))\n",
    "    next_gen=elite+tournament+randos\n",
    "    for program in range(len(next_gen)):\n",
    "        mut(next_gen[program])\n",
    "        if random.random() < XOVER_P:\n",
    "            program2 = random.randint(0, len(next_gen)-1)\n",
    "            XOver(next_gen[program], next_gen[program2])\n",
    "            logfile.write('Crossed ' + str(program) + ' and ' + str(program2) +'\\n')\n",
    "    generation += 1\n",
    "    population = next_gen\n",
    "    for program in population:\n",
    "        program.reset()\n",
    "    \n",
    "            \n",
    "logfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9c66375-6605-45ef-b9fa-489d44e63d1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-4.153151630887583, 1.0, 1.0, 24.36, 0.0, 4.935585071701226, -0.25, 0.0, -0.8414709848078965, 24.36, 0.0, 0.4112987559751021, -4.153151630887583, 4.153151630887583, 0.0, 0.0, 17.248668469144192, 1.6161982319408212, 0.0, 0.0, 0.6635116636975381, 4.935585071701226, 0.0, 0.0, -1.0, 1.0, 0.5, 0.3333333333333333, 0.25, 0.2, 12.18, 20.52, 77.22, 458.7, 0.08013, 0.04038, 0.02383, 0.0177, 0.1739, 0.05677, 0.1924, 1.571, 1.183, 14.68, 0.00508, 0.006098, 0.01069, 0.006797, 0.01447, 0.001532, 13.34, 32.84, 84.58, 547.8, 0.1123, 0.08862, 0.1145, 0.07431, 0.2694, 0.06878]\n",
       "Add(10,6,19)\n",
       "Min(18,14,10)\n",
       "Max(19,19,4)\n",
       "Mean(6,2,18)\n",
       "Sqrt(4,18,7)\n",
       "Div(19,7,11)\n",
       "Exp(3,4,13)\n",
       "Sub(7,28,17)\n",
       "Mean(2,13,20)\n",
       "Add(13,9,6)\n",
       "Copy(8,12,19)\n",
       "Sub(26,21,8)\n",
       "Log(13,6,23)\n",
       "Sqrt(13,4,1)\n",
       "Exp(19,25,2)\n",
       "Sin(19,0,15)\n",
       "Mean(15,15,11)\n",
       "Copy(14,19,14)\n",
       "Sqrt(12,16,11)\n",
       "Div(30,8,9)\n",
       "Sqrt(9,8,21)\n",
       "Mul(21,20,11)\n",
       "Min(23,1,6)\n",
       "Exp(14,12,5)\n",
       "Mean(3,30,17)\n",
       "Sin(24,6,8)\n",
       "Max(9,19,3)\n",
       "Mul(8,21,13)\n",
       "Min(25,10,0)\n",
       "Sqrt(15,7,13)\n",
       "Mean(12,21,20)\n",
       "Max(23,13,5)\n",
       "Exp(16,29,2)\n",
       "Add(0,12,12)\n",
       "Sqr(0,12,16)\n",
       "Div(12,24,13)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_prog_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10f63e23-d213-4f02-8c60-c1137191a9bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9878048780487805"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "program=best_prog_c\n",
    "outs = []\n",
    "for row in range(len(X_test)):\n",
    "    tv = y_test[row]           #true value of sin for the fitness case\n",
    "    #print(program)\n",
    "    program.reset()             #return value of the program evaluated on the fitness case\n",
    "    program._set_inputs(X_test[row])\n",
    "    #print(program)\n",
    "    rv = program.execute()\n",
    "    outs.append(rv) \n",
    "if (max(outs) - min(outs) != 0):\n",
    "    outs = [(float(i)-min(outs))/(max(outs)-min(outs)) for i in outs]\n",
    "elif max(outs) != 0:\n",
    "    outs = [(float(i))/(max(outs)) for i in outs]\n",
    "fitness_c = roc_auc_score(y_test, outs)\n",
    "fitness_c\n",
    "    #fitness_1 += math.sqrt((rv-tv)**2)\n",
    "\n",
    "#     for out in outs:\n",
    "#         if out in out_counts.keys():\n",
    "#             out_counts[out] += 1\n",
    "#         else:\n",
    "#             out_counts[out] = 1\n",
    "#     for out_count in out_counts.keys():\n",
    "#         if out_counts[out_count] > 1:\n",
    "#             fitness_2 += out_counts[out_count]**2\n",
    "# fitness = max([(1-(gen/F1_AMELIORATION)), 0])*fitness_2 + min([(gen/F1_AMELIORATION), 1])*fitness_1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a12b2973-0607-40fa-b68f-e360a067813a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_roc_and_precision_recall(y_true, y_score):\n",
    "    #Method from https://colab.research.google.com/github/gal-a/blog/blob/master/docs/notebooks/sklearn/sklearn_logistic_regression_vs_gbm.ipynb#scrollTo=-aBbV0bWBxwc\n",
    "    # Get ROC curve FPR and TPR from true labels vs score values\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_score)\n",
    "\n",
    "    # Calculate ROC Area Under the Curve (AUC) from FPR and TPR data points\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # Calculate precision and recall from true labels vs score values\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_score)\n",
    "\n",
    "    plt.figure(figsize=(8, 3))\n",
    "\n",
    "    plt.subplot(1,2,1)\n",
    "    lw = 2\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=lw, label='ROC curve (AUC = %0.4f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.step(recall, precision, color='orange', where='post')\n",
    "    # plt.fill_between(recall, precision, step='post', alpha=0.5, color='orange')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.title('Precision Recall Curve')\n",
    "    plt.grid(True)\n",
    "\n",
    "    left  = 0.125  # the left side of the subplots of the figure\n",
    "    right = 0.9    # the right side of the subplots of the figure\n",
    "    bottom = 0.1   # the bottom part of the subplots of the figure\n",
    "    top = 0.9      # the top part of the subplots of the figure\n",
    "    wspace = 0.5   # the amount of width reserved for blank space between subplots\n",
    "    hspace = 0.2   # the amount of height reserved for white space between subplots\n",
    "    plt.subplots_adjust(left, bottom, right, top, wspace, hspace)\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "\n",
    "plot_roc_and_precision_recall(y_test, outs)  # provide the column for the scores belonging only to the positive class\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61526a42-4035-48ec-9ca2-0975f1c47289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2.0 and 3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bba9f37a-2fe1-452f-aed5-2d478f275d22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3 < 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "53f32ed6-7f76-499e-bfde-2a9fc06564e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(3 < 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1765abcd-2de0-40c7-9ae8-6239e8924a05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
